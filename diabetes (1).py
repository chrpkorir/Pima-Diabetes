# -*- coding: utf-8 -*-
"""Diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JfxoDXFO_ic5eSWJZUQBgKJCODAtASge
"""

# Commented out IPython magic to ensure Python compatibility.
# import the libraries

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pickle
import os

# %matplotlib inline


from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.impute import SimpleImputer

# load the dataframe

df = pd.read_csv('diabetes.csv' )
df.head()

df.info()

# check if there are null values

df.isnull().values.any()

# pairplot to visualize my dataset
sns.pairplot(df)

# Get correlation of each features in the dataset
corr = df.corr()
top_corr_features = corr.index
plt.figure(figsize=(20,20))

# plot the heatmap

g = sns.heatmap(df[top_corr_features].corr(), annot=True, cmap="RdYlGn")
df.corr()

# Check if the dataset is balanced

diabetes_true_count = len(df.loc[df["Outcome"]==True])
diabetes_false_count = len(df.loc[df["Outcome"]==False])

(diabetes_true_count, diabetes_false_count)

# split the features from the targets
#features = df.drop('Outcome', axis=1)
#target = df['Outcome']

# split the dataset into feature and label variable
feature_cols = ['Pregnancies', 'Insulin', 'BloodPressure','BMI','Glucose','Age', 'SkinThickness', 'DiabetesPedigreeFunction']
predicted_class = ['Outcome']
X = df[feature_cols].values
y = df[predicted_class].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)



# Do imputation to the missing values

fill_values = SimpleImputer(missing_values=0, strategy="mean")
X_train = fill_values.fit_transform(X_train)
X_test = fill_values.fit_transform(X_test)

# Create pipeline
pipeline = make_pipeline(\
                         RobustScaler(),
                         SelectKBest(f_classif),
                         LogisticRegression(solver='lbfgs'))

# Instantiate the model
logreg = LogisticRegression()

logreg.fit(X_train, y_train)

# predict the output for our model

y_pred = logreg.predict(X_test)
y_pred

X_test

# To improve accuracy import the metrics class to create confusion matrix

cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

# plot the confusion matrix

class_names = [0,1] # names of classes
ax = plt.subplots
tick_marks = np.arange (len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

# Create a heatmap

sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu", fmt='g')

plt.tight_layout()
plt.title("Confusion matrix")
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

# test accuracy

accuracy = metrics.accuracy_score(y_test, y_pred)
print("accuracy = ", accuracy * 100, "%")

# Save the model
if not os.path.exists('models'):
  os.makedirs('models')

MODEL_PATH = "models/logistic_reg.save"
pickle.dump(logreg, open(MODEL_PATH,'wb'))